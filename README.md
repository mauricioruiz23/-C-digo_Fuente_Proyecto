Repositorio de Código Fuente del proyecto en GitHub. Instrucciones de ejecución:

Implementación del conjunto de datos en Spark.
Ejecutar el código nano batch_processing.py
Realizar operaciones de limpieza, transformación y análisis exploratorio de datos (EDA), utilizando RDDs o DataFrames. Almacenando los resultados procesados.
Ejecutar el código eda_spark.py
Implementar la aplicación Spark Streaming en un conjunto de datos que consume del tema de Kafka. Utilice el script en Python usando PySpark para compartir los datos de Kafka.
Ejecutar el código spark_kafka_streaming.py
Procesar los datos en tiempo real verificando los datos y visualizando los resultados del procesamiento.
Ejecutar el código procesamiento_streaming.py
